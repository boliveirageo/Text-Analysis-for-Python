{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando módulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os, scipy, nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from collections import defaultdict\n",
    "from heapq import nlargest\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções utilizadas no processamento "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criar um array das palavras \"expressão de busca\" \n",
    "def getSearchWords(dataframe,fieldtext):\n",
    "    \n",
    "    #Instanciando o objeto retirar palavras repetidas\n",
    "    txt2matriObj = CountVectorizer()\n",
    "    removestopwordsFull = []\n",
    "\n",
    "    for rows in dataframe[fieldtext]:\n",
    "        a = ''\n",
    "        for row in rows:a += row+' '\n",
    "        removestopwordsFull.append(a)\n",
    "        \n",
    "    txt2matri = txt2matriObj.fit_transform(removestopwordsFull)\n",
    "\n",
    "\n",
    "    #Retornando as palavras sem repeticao\n",
    "    return txt2matriObj.get_feature_names()\n",
    "\n",
    "#Criar um dataframe a partir de dados em formato .txt\n",
    "def preProcessingCorpus(folder,searchWords):\n",
    "\n",
    "    #Criando o arquivo\n",
    "    files = glob.glob(os.path.join(folder,'*.txt'))\n",
    "    \n",
    "    #Criando o nova dataframe\n",
    "    df = pd.DataFrame()\n",
    "    count = 0\n",
    "    \n",
    "    it = iter(searchWords) \n",
    "    zeros = [0]*len(searchWords)\n",
    "    obj = dict(zip(it,zeros))\n",
    "    \n",
    "    for i in obj.keys():obj[i] = [0]\n",
    "    \n",
    "    #Percorrendo todos os arquivo\n",
    "    for file in files:      \n",
    "    \n",
    "        #Coletando informacoes do contidas no arquivo e nome do arquivo com docid\n",
    "        data = open(file,'r',encoding='utf-8')\n",
    "        docid = str(os.path.basename(file)[0:-4])\n",
    "        year = str(docid.split('-')[2])\n",
    "    \n",
    "        #Inserindo valores no dataframe      \n",
    "        datas = pd.concat([pd.DataFrame({'id':[count],'docid':[docid],'text':[data.read()]}),pd.DataFrame(obj)],axis=1)\n",
    "        \n",
    "        df = df.append(datas)\n",
    "        datas = None\n",
    "    \n",
    "        #Fechando o arquivo\n",
    "        data.close()\n",
    "        count += 1\n",
    "    \n",
    "    return df\n",
    "\n",
    "#Processamento NLP (retirar os espaços entre as palavras, sufixos, stopwords)\n",
    "def processCorpus(dataframe,fieldtext):\n",
    "    \n",
    "    #Retirando espacos e colando as palavras minuscula\n",
    "    wpt = WordPunctTokenizer()\n",
    "    dataframe[fieldtext] = (dataframe[fieldtext].str.lower()).apply(wpt.tokenize) \n",
    "    \n",
    "    #Retirando os sufixos das palavras\n",
    "    stm = PorterStemmer()\n",
    "    texto_final_matrix = list()\n",
    "    for texto in dataframe[fieldtext]:    \n",
    "        texto_final = [stm.stem(txt) for txt in texto]\n",
    "        texto_final_matrix.append(texto_final)\n",
    "    dataframe[fieldtext] = texto_final_matrix\n",
    "\n",
    "    #Retirando as stopwords e as pontuacoes\n",
    "    #Coletando as stopword em Português\n",
    "    stopw = stopwords.words('portuguese') + list(punctuation)\n",
    "        \n",
    "    #Retirando as stopwords\n",
    "    palavras_sem_stopwords = []\n",
    "    for word_final in dataframe[fieldtext]:\n",
    "        palavras_sem_stopwords.append([word for word in word_final if word not in stopw])\n",
    "\n",
    "    dataframe[fieldtext] = palavras_sem_stopwords\n",
    "     \n",
    "    #Retornando o resultado da função    \n",
    "    return dataframe\n",
    "\n",
    "#Quantificar as palavras do texto\n",
    "def getCountWordsDocuments(dataframe,fieldtext,searchWords,FilterZero):\n",
    "    \n",
    "    #Frequencia das palavras\n",
    "    rows,cols = dataframe.shape\n",
    "    \n",
    "    #Percorrer todo o dataframe\n",
    "    for row in range(rows):    \n",
    "        \n",
    "        #Criando os objeto das palavras chaves\n",
    "        itetacao = iter(searchWords) \n",
    "        zeros = [0]*len(searchWords)\n",
    "        objs = dict(zip(itetacao,zeros))\n",
    "        for i in objs.keys():objs[i] = [0]\n",
    "        \n",
    "        #Set variavel dos textos de cada linha do dataframes\n",
    "        rowWord = dataframe.loc[dataframe['id'] == row,fieldtext]\n",
    "        words = [words for words in rowWord[0]]\n",
    "        \n",
    "        #Percorrer cada palavra do texto e quantifica as palavras chaves\n",
    "        for word in words:\n",
    "            if word in objs.keys():\n",
    "                objs[word] = [objs[word][0] + 1]\n",
    "            \n",
    "        #Atualizando o dataframe\n",
    "        if FilterZero:\n",
    "            value = max(objs.values())\n",
    "            if value == 0:\n",
    "                dataframe.drop(dataframe['id'] == row)\n",
    "            else:\n",
    "                dataframe.loc[dataframe['id'] == row,list(objs.keys())] = pd.DataFrame(objs)\n",
    "        else:    \n",
    "            dataframe.loc[dataframe['id'] == row,list(objs.keys())] = pd.DataFrame(objs)\n",
    "    \n",
    "    return dataframe\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando as Expressões de busca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:/Users/bernard-so/Documents/git/searchWords.csv',sep=';')\n",
    "searchWords = getSearchWords(processCorpus(df,'text'),'text')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'C:/Users/bernard-so/Documents/git/p/1992'\n",
    "data = preProcessingCorpus(folder,searchWords)\n",
    "Newdf = processCorpus(data,'text')\n",
    "Newdf = getCountWordsDocuments(Newdf,'text',searchWords,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Os 5 principais processos que tiveram a palavra 'trabalhista' com maior frequência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>docid</th>\n",
       "      <th>text</th>\n",
       "      <th>177</th>\n",
       "      <th>247</th>\n",
       "      <th>263</th>\n",
       "      <th>270</th>\n",
       "      <th>275</th>\n",
       "      <th>283</th>\n",
       "      <th>50</th>\n",
       "      <th>...</th>\n",
       "      <th>tcu</th>\n",
       "      <th>tempo</th>\n",
       "      <th>todo</th>\n",
       "      <th>trabalhista</th>\n",
       "      <th>técnica</th>\n",
       "      <th>unitário</th>\n",
       "      <th>visita</th>\n",
       "      <th>visto</th>\n",
       "      <th>vistoria</th>\n",
       "      <th>vínculo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1429</td>\n",
       "      <td>AC-528-1992-2</td>\n",
       "      <td>[tribun, conta, união, dado, materiai, decisão...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1467</td>\n",
       "      <td>AC-541-1992-P</td>\n",
       "      <td>[tribun, conta, união, dado, materiai, decisão...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1502</td>\n",
       "      <td>AC-557-1992-P</td>\n",
       "      <td>[tribun, conta, união, dado, materiai, decisão...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1610</td>\n",
       "      <td>AC-622-1992-P</td>\n",
       "      <td>[tribun, conta, união, dado, materiai, decisão...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1679</td>\n",
       "      <td>AC-83-1992-2</td>\n",
       "      <td>[tribun, conta, união, dado, materiai, decisão...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 117 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id          docid                                               text  \\\n",
       "0  1429  AC-528-1992-2  [tribun, conta, união, dado, materiai, decisão...   \n",
       "0  1467  AC-541-1992-P  [tribun, conta, união, dado, materiai, decisão...   \n",
       "0  1502  AC-557-1992-P  [tribun, conta, união, dado, materiai, decisão...   \n",
       "0  1610  AC-622-1992-P  [tribun, conta, união, dado, materiai, decisão...   \n",
       "0  1679   AC-83-1992-2  [tribun, conta, união, dado, materiai, decisão...   \n",
       "\n",
       "   177  247  263  270  275  283  50   ...     tcu  tempo  todo  trabalhista  \\\n",
       "0    0    0    0    0    0    0   0   ...       1      0     1           11   \n",
       "0    0    0    0    0    0    0   0   ...       0      1     0            8   \n",
       "0    0    0    0    0    0    0   0   ...       0     28     8            7   \n",
       "0    0    0    1    0    0    0   3   ...       1      0     5            6   \n",
       "0    0    0    0    0    0    0   0   ...       0      0     0            5   \n",
       "\n",
       "   técnica  unitário  visita  visto  vistoria  vínculo  \n",
       "0        1         0       0      0         0        0  \n",
       "0        0         0       0      0         0        0  \n",
       "0        1         0       0      0         0        0  \n",
       "0        2         3       0      0         2        0  \n",
       "0        0         0       0      0         0        0  \n",
       "\n",
       "[5 rows x 117 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Newdf.sort_values(['trabalhista'],ascending=0).head(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
